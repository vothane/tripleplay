{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tripleplay.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vothane/tripleplay/blob/master/tripleplay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEViyV7q6cGE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf040883-1ba6-4bf4-cfae-066d965460c9"
      },
      "source": [
        "from keras.layers import Dense, Input\n",
        "from keras.layers import Conv2D, Flatten\n",
        "from keras.layers import Reshape, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKnONoU6Q8qF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "e9e1f98d-e9b5-4ff9-9437-86dc0ee2b732"
      },
      "source": [
        "from keras.datasets import mnist # placeholding til I collected all pitch on\n",
        "                                 # strike zone maps\n",
        "(x_train, _), (x_test, _) = mnist.load_data() # DUMMY DATASET\n",
        "\n",
        "# reshape to ? and normalize input images\n",
        "image_size = x_train.shape[1]\n",
        "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
        "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# network parameters\n",
        "input_shape = (image_size, image_size, 1)\n",
        "batch_size = 32\n",
        "kernel_size = 3\n",
        "latent_dim = 16\n",
        "# encoder/decoder number of CNN layers and filters per layer\n",
        "layer_filters = [32, 64]\n",
        "\n",
        "# build the autoencoder model\n",
        "# first build the encoder model\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = inputs\n",
        "\n",
        "# stack of Conv2D(32)-Conv2D(64)\n",
        "for filters in layer_filters:\n",
        "    x = Conv2D(filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=2,\n",
        "               activation='relu',\n",
        "               padding='same')(x)\n",
        "\n",
        "# shape info needed to build decoder model so we don't do hand computation\n",
        "# the input to the decoder's first Conv2DTranspose will have this shape\n",
        "shape = K.int_shape(x)\n",
        "\n",
        "# generate the latent vector\n",
        "x = Flatten()(x)\n",
        "latent = Dense(latent_dim, name='latent_vector')(x)\n",
        "\n",
        "# instantiate encoder model\n",
        "encoder = Model(inputs, latent, name='encoder')\n",
        "encoder.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "latent_vector (Dense)        (None, 16)                50192     \n",
            "=================================================================\n",
            "Total params: 69,008\n",
            "Trainable params: 69,008\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnFIYsVld56-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "1e74a4ed-b170-4104-947c-8d9cbbc2ea58"
      },
      "source": [
        "# build the decoder model\n",
        "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
        "# use the shape (7, 7, 64) that was earlier saved\n",
        "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
        "# from vector to suitable shape for transposed conv\n",
        "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "# stack of Conv2DTranspose(64)-Conv2DTranspose(32)\n",
        "for filters in layer_filters[::-1]:\n",
        "    x = Conv2DTranspose(filters=filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        strides=2,\n",
        "                        activation='relu',\n",
        "                        padding='same')(x)\n",
        "\n",
        "# reconstruct the denoised input\n",
        "outputs = Conv2DTranspose(filters=1,\n",
        "                          kernel_size=kernel_size,\n",
        "                          padding='same',\n",
        "                          activation='sigmoid',\n",
        "                          name='decoder_output')(x)\n",
        "\n",
        "# instantiate decoder model\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3136)              53312     \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        18464     \n",
            "_________________________________________________________________\n",
            "decoder_output (Conv2DTransp (None, 28, 28, 1)         289       \n",
            "=================================================================\n",
            "Total params: 108,993\n",
            "Trainable params: 108,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}