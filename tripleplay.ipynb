{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tripleplay.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vothane/tripleplay/blob/master/tripleplay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEViyV7q6cGE",
        "colab_type": "code",
        "outputId": "caab0a90-3915-477b-80a0-85d2a7a8f02d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.layers import Dense, Input\n",
        "from keras.layers import Conv2D, Flatten\n",
        "from keras.layers import Reshape, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import os.path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qOkCPYBvZ01",
        "colab_type": "text"
      },
      "source": [
        "Run this cell only if you do not already have the image data.\n",
        "\n",
        "***Recommend that you not run this on your own machine.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJe4km5EqQw5",
        "colab_type": "code",
        "outputId": "4849cac6-aaf1-4c9b-9f86-5cf2e51530f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/vothane/tripleplay.git\n",
        "!mv tripleplay/imgs imgs\n",
        "!rm -rf tripleplay"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tripleplay'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
            "remote: Total 125 (delta 13), reused 105 (delta 3), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (125/125), 12.02 MiB | 31.81 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9t_mMwJBqb8",
        "colab_type": "code",
        "outputId": "98771101-7d91-48b7-f345-e27390faa5d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f = lambda img_file : img_to_array(load_img('imgs/{}'.format(img_file), color_mode = \"grayscale\"))\n",
        "pitcher_map = {img_file[:-4] : f(img_file)\n",
        "              for img_file in os.listdir('imgs/')}\n",
        "print(np.shape(pitcher_map['Chris_Sale']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(600, 600, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKnONoU6Q8qF",
        "colab_type": "code",
        "outputId": "dd1f3ae9-9955-45cb-aeaf-0d152fb20aaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "image_size = 600 # x=y\n",
        "\n",
        "# network parameters\n",
        "input_shape = (image_size, image_size, 1)\n",
        "batch_size = 32\n",
        "kernel_size = 3\n",
        "latent_dim = 16\n",
        "# encoder/decoder number of CNN layers and filters per layer\n",
        "layer_filters = [32, 64]\n",
        "\n",
        "# build the autoencoder model\n",
        "# first build the encoder model\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = inputs\n",
        "\n",
        "# stack of Conv2D(32)-Conv2D(64)\n",
        "for filters in layer_filters:\n",
        "    x = Conv2D(filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=2,\n",
        "               activation='relu',\n",
        "               padding='same')(x)\n",
        "\n",
        "# shape info needed to build decoder model so we don't do hand computation\n",
        "# the input to the decoder's first Conv2DTranspose will have this shape\n",
        "shape = K.int_shape(x)\n",
        "\n",
        "# generate the latent vector\n",
        "x = Flatten()(x)\n",
        "latent = Dense(latent_dim, name='latent_vector')(x)\n",
        "\n",
        "# instantiate encoder model\n",
        "encoder = Model(inputs, latent, name='encoder')\n",
        "encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0618 22:19:16.331130 140709518256000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0618 22:19:16.396432 140709518256000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0618 22:19:16.398235 140709518256000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 600, 600, 1)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 300, 300, 32)      320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 150, 150, 64)      18496     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1440000)           0         \n",
            "_________________________________________________________________\n",
            "latent_vector (Dense)        (None, 16)                23040016  \n",
            "=================================================================\n",
            "Total params: 23,058,832\n",
            "Trainable params: 23,058,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnFIYsVld56-",
        "colab_type": "code",
        "outputId": "2ad7f14c-e3e3-40b5-bd72-a1a0a903e153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# build the decoder model\n",
        "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
        "# use the shape (7, 7, 64) that was earlier saved\n",
        "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
        "# from vector to suitable shape for transposed conv\n",
        "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "# stack of Conv2DTranspose(64)-Conv2DTranspose(32)\n",
        "for filters in layer_filters[::-1]:\n",
        "    x = Conv2DTranspose(filters=filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        strides=2,\n",
        "                        activation='relu',\n",
        "                        padding='same')(x)\n",
        "\n",
        "# reconstruct the denoised input\n",
        "outputs = Conv2DTranspose(filters=1,\n",
        "                          kernel_size=kernel_size,\n",
        "                          padding='same',\n",
        "                          activation='sigmoid',\n",
        "                          name='decoder_output')(x)\n",
        "\n",
        "# instantiate decoder model\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1440000)           24480000  \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 150, 150, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 300, 300, 64)      36928     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 600, 600, 32)      18464     \n",
            "_________________________________________________________________\n",
            "decoder_output (Conv2DTransp (None, 600, 600, 1)       289       \n",
            "=================================================================\n",
            "Total params: 24,535,681\n",
            "Trainable params: 24,535,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Eef1o_iKSXH",
        "colab_type": "code",
        "outputId": "2a11d192-443c-4bd1-9784-3672f2c49b3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# autoencoder = encoder + decoder\n",
        "# instantiate autoencoder model\n",
        "autoencoder = Model(inputs,\n",
        "                    decoder(encoder(inputs)),\n",
        "                    name='autoencoder')\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 600, 600, 1)       0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 16)                23058832  \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 600, 600, 1)       24535681  \n",
            "=================================================================\n",
            "Total params: 47,594,513\n",
            "Trainable params: 47,594,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW5pQW0zJjGp",
        "colab_type": "code",
        "outputId": "ba38404a-5fb7-4d44-ab96-1ab5fadc69d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "# Mean Square Error (MSE) loss function, Adam optimizer\n",
        "autoencoder.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "train_data = np.array([data for _, data in pitcher_map.items()])\n",
        "\n",
        "autoencoder.fit(train_data, train_data, epochs=15, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 22:19:16.733934 140709518256000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0618 22:19:17.066696 140709518256000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0618 22:19:17.273879 140709518256000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "96/96 [==============================] - 66s 690ms/step - loss: 1385.6637\n",
            "Epoch 2/15\n",
            "96/96 [==============================] - 60s 630ms/step - loss: 1376.0912\n",
            "Epoch 3/15\n",
            "96/96 [==============================] - 60s 630ms/step - loss: 1375.0455\n",
            "Epoch 4/15\n",
            "96/96 [==============================] - 60s 629ms/step - loss: 1375.0734\n",
            "Epoch 5/15\n",
            "96/96 [==============================] - 60s 629ms/step - loss: 1375.0853\n",
            "Epoch 6/15\n",
            "96/96 [==============================] - 61s 631ms/step - loss: 1375.0903\n",
            "Epoch 7/15\n",
            "96/96 [==============================] - 60s 628ms/step - loss: 1375.0924\n",
            "Epoch 8/15\n",
            "96/96 [==============================] - 60s 627ms/step - loss: 1375.0930\n",
            "Epoch 9/15\n",
            "96/96 [==============================] - 60s 629ms/step - loss: 1375.0934\n",
            "Epoch 10/15\n",
            "96/96 [==============================] - 61s 632ms/step - loss: 1375.0935\n",
            "Epoch 11/15\n",
            "96/96 [==============================] - 60s 629ms/step - loss: 1375.0933\n",
            "Epoch 12/15\n",
            "96/96 [==============================] - 60s 626ms/step - loss: 1375.0933\n",
            "Epoch 13/15\n",
            "96/96 [==============================] - 60s 625ms/step - loss: 1375.0933\n",
            "Epoch 14/15\n",
            "96/96 [==============================] - 60s 627ms/step - loss: 1375.0931\n",
            "Epoch 15/15\n",
            "96/96 [==============================] - 60s 625ms/step - loss: 1375.0930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff937a85a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OEaEMLU4m0W",
        "colab_type": "text"
      },
      "source": [
        "first pass at tsne"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAbopDup4bhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "deep_features = encoder.predict(train_data, batch_size=batch_size)\n",
        "\n",
        "X_embedded = TSNE(n_components=2).fit_transform(deep_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TgVotl9EQ9C",
        "colab_type": "text"
      },
      "source": [
        "Really this is basically nearest neighbors where closet points are pitchers who closely resemble each other. I need to\n",
        "graph these points and label them with pitchers names to make sense of it all. after that we can ascertain what these \n",
        "deep features may be, right now there are 16 and we can use ensemble algos to find an optimal number after words. i'm guessing something like arm slot (3/4 or overhand) and left/right handedness. \n",
        "\n",
        "At second glance, features like arm slot (3/4 or overhand) and left/right handedness are actually linear regression features and should be learned at the topmost hidden layer. This is apparent by visual inspection, where data points can be \"regressed\" with straight diagonal line. \\ line would indicate right-handed pitcher and / would be \"southpaws\". Whereas angle of the line indicates arm-slot.\n",
        "\n",
        "Having said this, these simple features should still be inherent in non-linear complex features found in deeper hidden layers. For example, fastballs that have movement couldn't be linear regress by location, but should still be in the same region corresponding to pitching hand and arm slot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2q60ouA7Xl1",
        "colab_type": "code",
        "outputId": "1c39338a-4602-4f95-b7b0-9b13b04578b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1649
        }
      },
      "source": [
        "X_embedded"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0.64032364,  -3.0423017 ],\n",
              "       [ -0.6238203 ,  -3.1345475 ],\n",
              "       [ -5.8405695 ,  -3.4683228 ],\n",
              "       [ -5.496346  ,  -3.453512  ],\n",
              "       [-11.122296  ,  -3.7218232 ],\n",
              "       [  4.452808  ,  -2.756968  ],\n",
              "       [ -2.7616677 ,  -3.3432739 ],\n",
              "       [  4.7446485 ,  -2.8219342 ],\n",
              "       [ -1.2700698 ,  -3.2678251 ],\n",
              "       [  3.0896106 ,  -2.949368  ],\n",
              "       [ -8.820094  ,  -3.5099847 ],\n",
              "       [  1.5661067 ,  -2.7531717 ],\n",
              "       [  4.9882536 ,  -2.8956673 ],\n",
              "       [ -9.960251  ,  -3.6419225 ],\n",
              "       [ -8.175387  ,  -3.51783   ],\n",
              "       [  0.6044906 ,  -3.0672913 ],\n",
              "       [  1.1454474 ,  -2.759755  ],\n",
              "       [ -8.835623  ,  -3.7911541 ],\n",
              "       [ -3.0936744 ,  -3.3507838 ],\n",
              "       [ -6.166517  ,  -3.4972136 ],\n",
              "       [ -9.309842  ,  -3.7114441 ],\n",
              "       [-10.652346  ,  -3.7187488 ],\n",
              "       [  2.698557  ,  -2.6982803 ],\n",
              "       [ -9.756392  ,  -3.7535372 ],\n",
              "       [-10.343699  ,  -3.725908  ],\n",
              "       [ -6.2224417 ,  -3.4969952 ],\n",
              "       [ -5.975076  ,  -3.4825175 ],\n",
              "       [-10.312896  ,  -3.723547  ],\n",
              "       [  4.7851834 ,  -2.8299325 ],\n",
              "       [ -8.524791  ,  -3.4540935 ],\n",
              "       [ -5.553417  ,  -3.46138   ],\n",
              "       [-11.372183  ,  -3.723154  ],\n",
              "       [ -6.8591557 ,  -3.5641603 ],\n",
              "       [ -4.2908587 ,  -3.3752933 ],\n",
              "       [ -8.185291  ,  -3.6497588 ],\n",
              "       [  1.5655735 ,  -3.3933775 ],\n",
              "       [ -5.0272    ,  -3.4228246 ],\n",
              "       [ -7.1924214 ,  -3.5852273 ],\n",
              "       [  2.1116972 ,  -3.3716605 ],\n",
              "       [-11.46112   ,  -3.7237585 ],\n",
              "       [ -0.8973333 ,  -3.1350496 ],\n",
              "       [  3.346302  ,  -2.8023522 ],\n",
              "       [  0.02884666,  -3.0469384 ],\n",
              "       [ -0.5311336 ,  -3.1359816 ],\n",
              "       [ -3.9031467 ,  -3.3461092 ],\n",
              "       [  4.593775  ,  -2.788672  ],\n",
              "       [ -1.0188773 ,  -3.2457452 ],\n",
              "       [  3.3755057 ,  -2.7886832 ],\n",
              "       [  2.480985  ,  -3.38965   ],\n",
              "       [ -3.6712403 ,  -3.3266141 ],\n",
              "       [ -2.7374399 ,  -3.4078684 ],\n",
              "       [ -5.3720593 ,  -3.434451  ],\n",
              "       [  1.0015546 ,  -3.1162894 ],\n",
              "       [ -7.1667776 ,  -3.4766328 ],\n",
              "       [ -7.057412  ,  -3.5662982 ],\n",
              "       [ -4.6370687 ,  -3.394458  ],\n",
              "       [ -1.8709428 ,  -3.1282203 ],\n",
              "       [ -8.387585  ,  -3.7696855 ],\n",
              "       [ -9.443789  ,  -3.6586497 ],\n",
              "       [  1.9955639 ,  -2.6398056 ],\n",
              "       [-10.097419  ,  -3.706056  ],\n",
              "       [ -7.5573144 ,  -3.6643288 ],\n",
              "       [ -2.1175652 ,  -3.3417149 ],\n",
              "       [ -7.552099  ,  -3.6081161 ],\n",
              "       [-11.173538  ,  -3.722364  ],\n",
              "       [  2.9843698 ,  -3.0055258 ],\n",
              "       [ -5.2840276 ,  -3.4366007 ],\n",
              "       [-11.144962  ,  -3.722704  ],\n",
              "       [ -7.6465955 ,  -3.533197  ],\n",
              "       [  4.0669246 ,  -2.7135465 ],\n",
              "       [ -1.6911657 ,  -3.0431707 ],\n",
              "       [  2.1623685 ,  -2.7740948 ],\n",
              "       [ -1.4707013 ,  -3.3259194 ],\n",
              "       [  1.1101646 ,  -2.7867527 ],\n",
              "       [  1.6121866 ,  -2.7522705 ],\n",
              "       [  1.2147295 ,  -3.2420807 ],\n",
              "       [ -8.597463  ,  -3.813042  ],\n",
              "       [ -3.1118565 ,  -3.144165  ],\n",
              "       [ -2.3280044 ,  -3.4192686 ],\n",
              "       [  2.1390162 ,  -2.7089448 ],\n",
              "       [  4.183683  ,  -2.775864  ],\n",
              "       [ -0.2644066 ,  -3.1336594 ],\n",
              "       [ -9.993587  ,  -3.7259777 ],\n",
              "       [ -6.435061  ,  -3.5110564 ],\n",
              "       [ -1.2999331 ,  -3.2994194 ],\n",
              "       [ -2.5684233 ,  -3.142848  ],\n",
              "       [  1.2795992 ,  -3.2175715 ],\n",
              "       [  0.21977687,  -3.0896773 ],\n",
              "       [ -8.959287  ,  -3.6230133 ],\n",
              "       [ -3.5437791 ,  -3.3514557 ],\n",
              "       [ -2.394216  ,  -3.0738082 ],\n",
              "       [  2.1932137 ,  -2.6276014 ],\n",
              "       [  4.545514  ,  -2.7753036 ],\n",
              "       [  1.9411687 ,  -3.1885393 ],\n",
              "       [  2.3147032 ,  -3.224634  ],\n",
              "       [ -1.3308262 ,  -2.6825116 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}