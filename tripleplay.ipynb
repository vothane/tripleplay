{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tripleplay.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vothane/tripleplay/blob/master/tripleplay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEViyV7q6cGE",
        "colab_type": "code",
        "outputId": "3b4f3694-8f4a-43fe-ac74-3b52cd21f7e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.layers import Dense, Input\n",
        "from keras.layers import Conv2D, Flatten\n",
        "from keras.layers import Reshape, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import os.path"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qOkCPYBvZ01",
        "colab_type": "text"
      },
      "source": [
        "Run this cell only if you do not already have the image data.\n",
        "\n",
        "***Recommend that you not run this on your own machine.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJe4km5EqQw5",
        "colab_type": "code",
        "outputId": "eec70e48-cdbb-4bc9-9362-f08902965cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/vothane/tripleplay.git\n",
        "!mv tripleplay/imgs imgs\n",
        "!rm -rf tripleplay"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tripleplay'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 128 (delta 15), reused 105 (delta 3), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (128/128), 12.02 MiB | 29.81 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9t_mMwJBqb8",
        "colab_type": "code",
        "outputId": "b75aa601-8f4f-4db5-9195-d9e25d319194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f = lambda img_file : img_to_array(load_img('imgs/{}'.format(img_file), color_mode = \"grayscale\"))\n",
        "pitcher_map = {img_file[:-4] : f(img_file)\n",
        "              for img_file in os.listdir('imgs/')}\n",
        "print(np.shape(pitcher_map['Chris_Sale']))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(600, 600, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKnONoU6Q8qF",
        "colab_type": "code",
        "outputId": "0ee7f70b-27cf-4d23-b1ac-7ce4b826425d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "image_size = 600 # x=y\n",
        "\n",
        "# network parameters\n",
        "input_shape = (image_size, image_size, 1)\n",
        "batch_size = 32\n",
        "kernel_size = 3\n",
        "latent_dim = 16\n",
        "# encoder/decoder number of CNN layers and filters per layer\n",
        "layer_filters = [32, 64]\n",
        "\n",
        "# build the autoencoder model\n",
        "# first build the encoder model\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = inputs\n",
        "\n",
        "# stack of Conv2D(32)-Conv2D(64)\n",
        "for filters in layer_filters:\n",
        "    x = Conv2D(filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=2,\n",
        "               activation='relu',\n",
        "               padding='same')(x)\n",
        "\n",
        "# shape info needed to build decoder model so we don't do hand computation\n",
        "# the input to the decoder's first Conv2DTranspose will have this shape\n",
        "shape = K.int_shape(x)\n",
        "\n",
        "# generate the latent vector\n",
        "x = Flatten()(x)\n",
        "latent = Dense(latent_dim, name='latent_vector')(x)\n",
        "\n",
        "# instantiate encoder model\n",
        "encoder = Model(inputs, latent, name='encoder')\n",
        "encoder.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0619 20:21:54.634165 139890405009280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0619 20:21:54.701628 139890405009280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0619 20:21:54.705191 139890405009280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 600, 600, 1)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 300, 300, 32)      320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 150, 150, 64)      18496     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1440000)           0         \n",
            "_________________________________________________________________\n",
            "latent_vector (Dense)        (None, 16)                23040016  \n",
            "=================================================================\n",
            "Total params: 23,058,832\n",
            "Trainable params: 23,058,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnFIYsVld56-",
        "colab_type": "code",
        "outputId": "8afb6ca7-05b9-47f0-90c1-3eab0f753916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# build the decoder model\n",
        "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
        "# use the shape (7, 7, 64) that was earlier saved\n",
        "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
        "# from vector to suitable shape for transposed conv\n",
        "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "# stack of Conv2DTranspose(64)-Conv2DTranspose(32)\n",
        "for filters in layer_filters[::-1]:\n",
        "    x = Conv2DTranspose(filters=filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        strides=2,\n",
        "                        activation='relu',\n",
        "                        padding='same')(x)\n",
        "\n",
        "# reconstruct the denoised input\n",
        "outputs = Conv2DTranspose(filters=1,\n",
        "                          kernel_size=kernel_size,\n",
        "                          padding='same',\n",
        "                          activation='sigmoid',\n",
        "                          name='decoder_output')(x)\n",
        "\n",
        "# instantiate decoder model\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1440000)           24480000  \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 150, 150, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 300, 300, 64)      36928     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 600, 600, 32)      18464     \n",
            "_________________________________________________________________\n",
            "decoder_output (Conv2DTransp (None, 600, 600, 1)       289       \n",
            "=================================================================\n",
            "Total params: 24,535,681\n",
            "Trainable params: 24,535,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Eef1o_iKSXH",
        "colab_type": "code",
        "outputId": "80d832fb-ffc6-4bf4-afe3-6dd851542e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# autoencoder = encoder + decoder\n",
        "# instantiate autoencoder model\n",
        "autoencoder = Model(inputs,\n",
        "                    decoder(encoder(inputs)),\n",
        "                    name='autoencoder')\n",
        "autoencoder.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 600, 600, 1)       0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 16)                23058832  \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 600, 600, 1)       24535681  \n",
            "=================================================================\n",
            "Total params: 47,594,513\n",
            "Trainable params: 47,594,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW5pQW0zJjGp",
        "colab_type": "code",
        "outputId": "5c151439-3cca-477b-a975-57fd6cf56c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "# Mean Square Error (MSE) loss function, Adam optimizer\n",
        "autoencoder.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "train_data = np.array([data for _, data in pitcher_map.items()])\n",
        "\n",
        "autoencoder.fit(train_data, train_data, epochs=15, batch_size=batch_size)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0619 20:21:55.082233 139890405009280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0619 20:21:55.425490 139890405009280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0619 20:21:55.635042 139890405009280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "96/96 [==============================] - 69s 718ms/step - loss: 1378.4033\n",
            "Epoch 2/15\n",
            "96/96 [==============================] - 63s 653ms/step - loss: 1374.8607\n",
            "Epoch 3/15\n",
            "96/96 [==============================] - 62s 650ms/step - loss: 1374.7433\n",
            "Epoch 4/15\n",
            "96/96 [==============================] - 63s 652ms/step - loss: 1374.6403\n",
            "Epoch 5/15\n",
            "96/96 [==============================] - 62s 649ms/step - loss: 1374.6078\n",
            "Epoch 6/15\n",
            "96/96 [==============================] - 62s 649ms/step - loss: 1374.5765\n",
            "Epoch 7/15\n",
            "96/96 [==============================] - 62s 649ms/step - loss: 1374.5402\n",
            "Epoch 8/15\n",
            "96/96 [==============================] - 62s 648ms/step - loss: 1374.5432\n",
            "Epoch 9/15\n",
            "96/96 [==============================] - 62s 648ms/step - loss: 1374.5475\n",
            "Epoch 10/15\n",
            "96/96 [==============================] - 62s 651ms/step - loss: 1374.5508\n",
            "Epoch 11/15\n",
            "96/96 [==============================] - 62s 651ms/step - loss: 1374.5529\n",
            "Epoch 12/15\n",
            "96/96 [==============================] - 62s 650ms/step - loss: 1374.5538\n",
            "Epoch 13/15\n",
            "96/96 [==============================] - 62s 651ms/step - loss: 1374.5543\n",
            "Epoch 14/15\n",
            "96/96 [==============================] - 63s 653ms/step - loss: 1374.5551\n",
            "Epoch 15/15\n",
            "96/96 [==============================] - 62s 648ms/step - loss: 1374.5551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a7ff9abe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OEaEMLU4m0W",
        "colab_type": "text"
      },
      "source": [
        "# Motivation for using tSNE\n",
        "\n",
        "AI (hate that term) is neither good nor evil. But they do reflect on our society. Including social bias, unfairness and discrimination. Mostly unintentional, either by laziness or carelessness. Sometimes with malicious intent, for example ***Palantir***, the most perverse use of this technology.\n",
        "\n",
        "Iâ€™m not going too much into the societal implications but will introduce some tools and strategies to weed out undesirable learning dynamics. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAbopDup4bhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "deep_features = encoder.predict(train_data, batch_size=batch_size)\n",
        "\n",
        "X_embedded = TSNE(n_components=2).fit_transform(deep_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TgVotl9EQ9C",
        "colab_type": "text"
      },
      "source": [
        "Really this is basically nearest neighbors where closet points are pitchers who closely resemble each other. I need to\n",
        "graph these points and label them with pitchers names to make sense of it all. after that we can ascertain what these \n",
        "deep features may be, right now there are 16 and we can use ensemble algos to find an optimal number after words. i'm guessing something like arm slot (3/4 or overhand) and left/right handedness. \n",
        "\n",
        "At second glance, features like arm slot (3/4 or overhand) and left/right handedness are actually linear regression features and should be learned at the topmost hidden layer. This is apparent by visual inspection, where data points can be \"regressed\" with straight diagonal line. \\ line would indicate right-handed pitcher and / would be \"southpaws\". Whereas angle of the line indicates arm-slot.\n",
        "\n",
        "Having said this, these simple features should still be inherent in non-linear complex features found in deeper hidden layers. For example, fastballs that have movement couldn't be linear regress by location, but should still be in the same region corresponding to pitching hand and arm slot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL2S_mMQg9aY",
        "colab_type": "text"
      },
      "source": [
        "Use K-Means clustering to see how many types of pitchers (categories) we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1XjwkxpZi43",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c2bcb21-035f-4075-bfc5-ca8bb009e7d9"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(random_state=0).fit(X_embedded)\n",
        "len(kmeans.cluster_centers_)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}